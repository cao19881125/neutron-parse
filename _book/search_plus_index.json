{"./":{"url":"./","title":"前言","keywords":"","body":"neutron源码解析 本书主要从neutron代码层面入手，通过分析neutron代码的架构设计、模块/插件设计、对象设计、业务流程、函数属性等，将neutron以及背后的sdn技术进行剖析 本书面向的读者为： 对openstack neutron有一定的部署、操作经验，希望了解其内部架构的 对neutron设计到的sdn技术，如openvswitch,linuxbridge,ovn等感兴趣，希望进行学习的 需要对neutron代码进行开发改造的 通过本书你将学习到如下内容 neutron用到的openstack公共模块，如:oslo-config,oslo-db,oslo-log,oslo-messing,oslo-service等 neutron的模块及插件设计，包括:core-plugin,service-plugin,mechanism-driver 等，以及他们的内部架构 neutron包含的sdn技术，以及这些技术相对的业务架构，如linux-bridge，openvswitch,ovn等 如何自己开发一款mechanism-driver插件 备注： 本书使用的代码为openstack ocata版本 笔者学习的思路一般为不管三七二十一先写测试代码，把测试代码跑起来，然后再反过头来分析，这样的好处是能先有一些成就感，然后更有动力去学习其中的原理 所以本书也按照这个思路，会放一些例子代码上来，并且附上测试运行的过程，然后再来分析其中的原理 由于某些函数的代码量比较大不便于阅读，所以我会精简代码，包括函数定义中去掉不相关的参数，函数实现中去掉不相关的异常处理、不相关的逻辑处理，将类或者函数重新排版等，只将重要的部分纳入进来 作者：曹云涛，Github @cao 邮件：caoyuntao1125@gmail.com 本书github地址: neutron-parse By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 14:32:38 "},"forward.html":{"url":"forward.html","title":"序章","keywords":"","body":"序章 neutron中的模块关系 本书主要通过如下列举的模块进行分析，各模块的关系和功能如下所示 oslo-service: 负责创建wsgi服务，接收restful api的调用 paste deploy: 对restful api进行过滤，调用对应的后端函数，其中包括token校验，校验成功后，调用到core-plugin对应的函数 core-plugin: ml2业务代码入口，包括network、subnet、port的处理 service-plugin: 其他业务的代码入口，如l3层的router、floating ip、security group 操作等 mechanism driver:底层sdn实现的技术，目前主流的技术有linux-bridge,openvswitch,ovn等 oslo-config: 配置文件解析 oslo-log:日志处理 oslo-db:数据库处理 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-08 14:02:07 "},"common_lib/oslo_config/config.html":{"url":"common_lib/oslo_config/config.html","title":"安装","keywords":"","body":" oslo-config是一个openstack的公共库，用于从命令行或者配置文件中解析配置选项 安装 pip install oslo-config 安装完查看版本 # pip show oslo-config Name: oslo.config Version: 6.0.1 Summary: Oslo Configuration API Home-page: https://docs.openstack.org/oslo.config/latest/ Author: OpenStack Author-email: openstack-dev@lists.openstack.org License: UNKNOWN Location: /usr/local/lib/python2.7/site-packages Requires: enum34, debtcollector, oslo.i18n, netaddr, PyYAML, rfc3986, six, stevedore Required-by: ryu, python-keystoneclient, pycadf, oslo.versionedobjects, oslo.service, oslo.privsep, oslo.policy, oslo.middleware, oslo.messaging, oslo.log, oslo.db, oslo.concurrency, oslo.cache, neutron, neutron-lib, keystonemiddleware By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-05 18:12:13 "},"common_lib/oslo_config/example.html":{"url":"common_lib/oslo_config/example.html","title":"例子","keywords":"","body":"例子 以下两个例子演示了通过两种方式使用oslo-config模块的方法，分别为通过命令行传递参数和通过配置文件传递参数 cli传递参数 oslo-config可以通过读取命令行来获取参数，例子代码如下 编写osloclitest.py import sys from oslo_config import cfg cli_opts = [cfg.StrOpt('option1'), cfg.IntOpt('option2', default=42)] cfg.CONF.register_cli_opts(cli_opts) cfg.CONF(sys.argv[1:]) print(\"The value of option1 is %s\" % cfg.CONF.option1) print(\"The value of option2 is %d\" % cfg.CONF.option2) 运行 # python osloclitest.py --option1 100 The value of option1 is 100 The value of option2 is 42 可以看到通过命令行指定了option1为100，没有指定option2，option2使用了默认值42 解析 cli_opts是参数列表，类型是字典，每个参数是又cfg中定义的类型 这里定义了两个参数，其中option1是string类型，option2为int类型，并且通过default属性给option2指定了默认值 通过register_cli_opts将cli_opts注册为命令行参数 sys.argv[1:]表示所有的启动参数，传入cfg.CONF模块 在代码中直接通过cfg.CONF.变量名的形式进行变量访问 cli命令中，如果不通过命令行指定参数: 如果参数有默认值，如option2，则使用默认值 如果参数没有默认值，则值为None cli命令中，指定了参数的话，则使用命令行的值，无论是否有默认值 通过配置文件传递参数 官网给出了一个简单的例子 编写oslocfgtest.py文件 import sys from oslo_config import cfg grp = cfg.OptGroup('mygroup') opts = [cfg.StrOpt('option1'), cfg.IntOpt('option2', default=42)] cfg.CONF.register_group(grp) cfg.CONF.register_opts(opts, group=grp) cfg.CONF.register_opt(cfg.BoolOpt('option3')) cfg.CONF(sys.argv[1:]) print(\"The value of option1 is %s\" % cfg.CONF.mygroup.option1) print(\"The value of option2 is %d\" % cfg.CONF.mygroup.option2) print(\"The value of option3 is %s\" % str(cfg.CONF.option3)) 编写oslocfgtest.conf配置文件 [DEFAULT] option3 = true [mygroup] option1 = foo # Comment out option2 to test the default value # option2 = 123 run python oslocfgtest.py --config-file oslocfgtest.conf output The value of option1 is foo The value of option2 is 42 创建了一个名为oslocfgtest.conf的配置文件，并且在配置文件中配置了两个组，DEFAULT组合mygroup组 DEFAULT组下定义了一个参数为option3 mygroup组下面有一个参数option1并且值设为了foo 在代码中先分别定义了一个mygroup组和option1，option2两个变量，option2变量指定了默认值 通过register_opts函数注册了mygroup组和两个变量，并且将变量与mygroup组进行了绑定 通过register_opt函数注册了一个DEFAULT组的变量option3 通过sys.argv[1:]取到了命令行参数，传给cfg模块 直接用cfg.CONF.组名.变量名进行变量访问 如果不加组名，则默认是DEFAULT组下的变量 如果指定了默认值，则在文件中没有进行重新定义变量的情况下，使用默认值，否则使用文件中定义的值 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-08 15:41:34 "},"common_lib/oslo_config/value_type.html":{"url":"common_lib/oslo_config/value_type.html","title":"变量类型","keywords":"","body":"参数类型 oslo-config中支持多种类型，所有支持的类型列举如下 boolean value (BoolOpt) Enables or disables an option. The allowed values are true and false. # Enable the experimental use of database reconnect on # connection lost (boolean value) use_db_reconnect = false floating point value (FloatOpt) A floating point number like 0.25 or 1000. # Sleep time in seconds for polling an ongoing async task # (floating point value) task_poll_interval = 0.5 integer value (IntOpt) An integer number is a number without fractional components, like 0 or 42. # The port which the OpenStack Compute service listens on. # (integer value) compute_port = 8774 IP address (IPOpt) An IPv4 or IPv6 address. # Address to bind the server. Useful when selecting a particular network # interface. (ip address value) bind_host = 0.0.0.0 key-value pairs (DictOpt) A key-value pairs, also known as a dictionary. The key value pairs are separated by commas and a colon is used to separate key and value. Example: key1:value1,key2:value2. # Parameter for l2_l3 workflow setup. (dict value) l2_l3_setup_params = data_ip_address:192.168.200.99, \\ data_ip_mask:255.255.255.0,data_port:1,gateway:192.168.200.1,ha_port:2 list value (ListOpt) Represents values of other types, separated by commas. As an example, the following sets allowed_rpc_exception_modules to a list containing the four elements oslo.messaging.exceptions, nova.exception, cinder.exception, and exceptions: # Modules of exceptions that are permitted to be recreated # upon receiving exception data from an rpc call. (list value) allowed_rpc_exception_modules = oslo.messaging.exceptions,nova.exception multi valued (MultiStrOpt) A multi-valued option is a string value and can be given more than once, all values will be used. # Driver or drivers to handle sending notifications. (multi valued) notification_driver = nova.openstack.common.notifier.rpc_notifier notification_driver = ceilometer.compute.nova_notifier port value (PortOpt) A TCP/IP port number. Ports can range from 1 to 65535. # Port to which the UDP socket is bound. (port value) # Minimum value: 1 # Maximum value: 65535 udp_port = 4952 string value (StrOpt) Strings can be optionally enclosed with single or double quotes. # The format for an instance that is passed with the log message. # (string value) instance_format = \"[instance: %(uuid)s] \" By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-05 18:19:40 "},"common_lib/oslo_config/cfg_conf.html":{"url":"common_lib/oslo_config/cfg_conf.html","title":"cfg.CONF实现解析","keywords":"","body":"cfg.CONF解析 本章对cfg.CONF的一些关键函数进行了分析，目标是通过本章的学习，能够了解到一些cfg.CONF关键部分的代码细节 cfg.CONF与arpparse 首先进行说明一下，cfg.CONF是通过argparse来实现的，后面的讲解将围绕如何通过argparse来实现命令行与文件解析，这里先简单介绍一下argparse argparse 是 Python 内置的一个用于命令项选项与参数解析的模块，通过在程序中定义好我们需要的参数，argparse 将会从 sys.argv 中解析出这些参数，并自动生成帮助和使用信息。 简单示例 import argparse parser = argparse.ArgumentParser() parser.add_argument('integer', type=int, help='display an integer') args = parser.parse_args() print args.integer 使用argparse主要有四个步骤 创建 ArgumentParser() 对象 调用 add_argument() 方法添加参数 使用 parse_args() 解析参数 通过返回值args.变量名来获取变量 cfg.CONF的实现 上一节我们讲解了argparse的四个步骤，本节我们将分析cfg.CONF的处理方式，并结合上节的四个关键步骤来分析cfg.CONF是如何实现的 对象定义 cfg.CONF的定义在oslo_config/cfg.py中，如下 CONF = ConfigOpts() 在cfg.py文件的最后一行，定义了CONF这个全局对象，初始化的类为ConfigOpts 注册变量 我们通过cfg.CONF.register_opt来注册单个变量，代码如下 DEFAULT group的处理 创建默认属性时，group不填或者填None，即表示创建在DEFAULT组 # oslo_config/cfg.py class ConfigOpts(collections.Mapping): disallow_names = ('project', 'prog', 'version', 'usage', 'default_config_files', 'default_config_dirs') def register_opt(self, opt, group=None, cli=False): # ... if group is None: if opt.name in self.disallow_names: raise ValueError('Name %s was reserved for oslo.config.' % opt.name) # ... self._opts[opt.dest] = {'opt': opt, 'cli': cli} # ... 先跟disallow_names比较一下看一下变量名是不是合法的 opt.dest 获取的是变量名，有一个小处理，即将变量名中的'-'替换成'_'，如下 class Opt(object): def __init__(self, name): self.name = name self.dest = self.name.replace('-', '_') # ... 将opt.dest作为key保存到self._opts字典中，value为opt对象 非DEFAULT group处理 调用register_opt时传入group属性，则将此变量和对应的group进行关联 # oslo_config/cfg.py class ConfigOpts(collections.Mapping): def register_opt(self, opt, group=None, cli=False): if group is not None: group = self._get_group(group, autocreate=True) if cli: self._add_cli_opt(opt, group) return group._register_opt(opt, cli) # ... def _get_group(self, group_or_name, autocreate=False): group = group_or_name group_name = group.name if group_name not in self._groups: self.register_group(group or OptGroup(name=group_name)) return self._groups[group_name] def register_group(self, group): if group.name in self._groups: return self._groups[group.name] = copy.copy(group) class OptGroup(object): def _register_opt(self, opt, cli=False): self._opts[opt.dest] = {'opt': opt, 'cli': cli} return True register_opt的group为OptGroup类型 通过register_group函数创建group，保存到self._groups中 并通过OptGroup._register_opt将变量注册到self._opts中 注册变量总结 ConfigOpts类有两个字典： self._opts字典保存DEFAULT组的变量，key为变量名，value为变量对象 self._groups字典保存所有的组，key为组名，value为组对应的OptGroup对象 OptGroup类有一个字典，self._opts保存这个组的变量，字典结构同ConfigOpts._opts 所有的注册变量，都会按照以上的结构保存在cfg.CONF这个对象中 配置命令行参数 命令行参数是通过如下方式传递给ConfigOpts的 cfg.CONF(sys.argv[1:]) 这里用到了python的可调用对象特性，即我们可以通过在对象后加()的方式，像调用函数一样调用对象 当如此调用对象时，对象的__call__方法得到调用 从这里开始，cfg.CONF将开始与argparse产生关联 第一步：自定义ArgumentParser 和 Action class _CachedArgumentParser(argparse.ArgumentParser) 扩展了ArgumentParser实现了_CachedArgumentParser __call__ -> self._pre_setup 中进行了初始化 self._oparser = _CachedArgumentParser() 同时自定义了两个Action 分别为ConfigFileAction和ConfigDirAction，顾名思义，这两个Action是分别对文件和目录进行处理的 class ConfigFileAction(argparse.Action) class ConfigDirAction(argparse.Action) argparser内部实现了很多action，默认的action为store，即保存参数值 cfg扩展实现了Action，实现了两个action，分别为ConfigFileAction和ConfigDirAction，分别对应命令行中的--config-file和--config-dir命令 第二步：添加注册命令行参数 初始化_ConfigFileOpt和_ConfigDirOpt 这两个Option分别是处理文件和目录的，他们关联了上节两个action，后面将讲解如果通过这两个action解析文件和目录 self._config_opts = self._make_config_options(default_config_files, default_config_dirs) def _make_config_options(default_config_files, default_config_dirs): return [ _ConfigFileOpt('config-file', default=default_config_files, metavar='PATH', help=('Path to ...')), _ConfigDirOpt('config-dir', metavar='DIR', default=default_config_dirs, help='Path to ...'), ] 构造action __call__ -> self._parse_cli_opts(args) self._args = args for opt, group in self._all_cli_opts(): opt._add_to_cli(self._oparser, group) 在neutron启动命令中，cli opts中只有--config-file ，我们先假设只有--config-file而没有其他的opt 那么opt的类型就是_ConfigFileOpt，调用到的是其父类Opt的_add_to_cli函数 class Opt(object): def _add_to_cli(self, parser, group=None): container = self._get_argparse_container(parser, group) kwargs = self._get_argparse_kwargs(group) # ... self._add_to_argparse(parser, container, self.name, self.short, kwargs, prefix, self.positional, deprecated_names) container在DEFAULT组情况下，获取到的还是_CachedArgumentParser self._get_argparse_kwargs这里，调用到的是_ConfigFileOpt多态实现的_get_argparse_kwargs函数 class _ConfigFileOpt(Opt): def _get_argparse_kwargs(self, group, **kwargs): kwargs = super(_ConfigFileOpt, self)._get_argparse_kwargs(group) kwargs['action'] = self.ConfigFileAction return kwargs 可以看到这里创建了action为ConfigFileAction并通过字典返回 继续通过self._add_to_argparse -> _CachedArgumentParser.add_parser_argument class _ConfigFileOpt(Opt): def _add_to_argparse(self, parser, container, name,...) # ... args = [hyphen('--') + prefix + name] # ... parser.add_parser_argument(container, *args, **kwargs) class _CachedArgumentParser(argparse.ArgumentParser): def add_parser_argument(self, container, *args, **kwargs): values = [] values.append({'args': args, 'kwargs': kwargs}) self._args_cache[container] = values self.name为'config-file'，在前面加上--，符合argparser的用法 到这里，args和ConfigFileAction保存在了self._args_cache中 通过add_argument注册参数 通过以上几步构造出来了调用argparser.add_argument的几个关键参数，下面就要对其进行注册 还是回到ConfigOpts.call函数，继续向下走 call -> self._parse_cli_opts(args) -> self._parse_config_files() -> self._oparser.parse_args(self._args, namespace) -> _CachedArgumentParser.parse_args(self, args=None, namespace=None) -> _CachedArgumentParser.initialize_parser_arguments(self) class _CachedArgumentParser(argparse.ArgumentParser): def initialize_parser_arguments(self): for container, values in self._args_cache.items(): # ... container.add_argument(*argument['args'],**argument['kwargs']) # ... 因为container就是_CachedArgumentParser，其父类是argparse.ArgumentParser，这个函数相当于是在argparser中注册了一个命令行参数，并且通过kwargs中的action注册了action为ConfigFileAction 第三步：解析参数和文件 通过上面的解释，已经知道了如何通过扩展的argparse.ArgumentParser将命令行参数'--config-file'和自定义的ConfigFileAction注册进去，本节讲解如何解析文件 在argparse中，参数只会通过命令行传递，只需要解析命令行参数即可 在cfg.CONF的实现中，是通过命令行传递的配置文件路径，cfg.CONF解析出来路径后，通过自定义的ConfigFileAction回调解析对应的配置文件，获取参数 在这里，因为是通过_CachedArgumentParser扩展了ArgumentParser，所以要找到如何通过_CachedArgumentParser调用到ArgumentParser.parse_args() 还是顺着call函数进行梳理 __call__ -> self._parse_cli_opts(args) -> self._parse_config_files() -> self._oparser.parse_args(self._args, namespace) -> _CachedArgumentParser.parse_args(self, args=None, namespace=None) class _CachedArgumentParser(argparse.ArgumentParser): def parse_args(self, args=None, namespace=None): self.initialize_parser_arguments() return super(_CachedArgumentParser, self).parse_args(args, namespace) 可以看到，initialize_parser_arguments是注册变量的最后一步，后面紧接着调用了父类，即ArgumentParser的parse_args()函数 这个函数的调用会进入到argparser的栈中，我们暂不分析 argparser经过一系列处理，最终会调用到自定义action的call方法，我们上面分析了，在这里的自定义action为ConfigFileAction class ConfigFileAction(argparse.Action): def __call__(self, parser, namespace, values, option_string=None): ... ConfigParser._parse_file(values, namespace) 这里调用到了ConfigParser进行文件解析 class ConfigParser(iniparser.BaseParser): @classmethod def _parse_file(cls, config_file, namespace): ... parser = cls(config_file, sections) arser.parse() ... namespace._add_parsed_config_file(config_file, sections, normalized) 这里构造一个ConfigParser的实例，并调用parse解析文件 parse的代码就不贴了，大概的意思是通过iniparser.BaseParser这个python库将文件进行读取分析，并保存到self.sections中，解析后的结果如下所示 {'DEFAULT': {'option3': ['true']}, 'mygroup': {'option1': ['foo']}} 即字典的key为组名，value为值的字典，value的字典以变量名为key，值为value 然后调用namespace的_add_parsed_config_file函数 class _Namespace(argparse.Namespace): def _add_parsed_config_file(self, filename, sections, normalized): for s in sections: self._sections_to_file[s] = filename self._parsed.insert(0, sections) self._normalized.insert(0, normalized) 通过这个函数，sections被保存到了self._parsed中 第四步：获取变量 通过以上的解析，已经知道了cfg.CONF如何通过命令行中的'--config-file'解析配置文件参数的，本节介绍如何获取参数，以如下的形式 cfg.CONF.mygroup.option1 cfg.CONF.mygroup.option2 cfg.CONF.option3 当直接以.来访问变量时，python会调用内置函数getattr，则ConfigOpts.getattr得到响应 class ConfigOpts(collections.Mapping): def __getattr__(self, name): return self._get(name) def _get(self, name, group=None, namespace=None): if isinstance(group, OptGroup): key = (group.name, name) else: key = (group, name) value, loc = self._do_get(name, group, namespace) return value def _do_get(self, name, group=None, namespace=None): # ... val, alt_loc = opt._get_from_namespace(namespace, group_name) return (convert(val), alt_loc) # ... 通过getattr一路调用到了Opt._get_from_namespace 次数的Opt是name所对应类型的Opt扩展类，如option3即BoolOpt class Opt(object): def _get_from_namespace(self, namespace, group_name): # ... value, loc = namespace._get_value( names, multi=self.multi, positional=self.positional, current_name=current_name) # ... return (value, loc) 调用到了namespace的_get_value方法 class _Namespace(argparse.Namespace): def _get_value(self, names, multi=False, positional=False, current_name=None, normalized=True): # ... values, loc = self._get_file_value( file_names, multi=multi, normalized=normalized, current_name=current_name) # ... return (values if multi else values[-1], loc) def _get_file_value(self, names): # ... for sections in (self._normalized if normalized else self._parsed): for section, name in names: # ... val = sections[section][name] # ... if multi and rvalue != []: return (rvalue, loc) 从namespace中的self._parsed中，取到对应group和name的值 在文件解析章节，最终文件解析的结果是将文件中的值保存到了self._parsed中，此处即从self._parsed中再取出来 总结 通过以上的分析，梳理了cfg.CONF从'--config-file'参数获取文件名，到解析文件中的值，到取值的过程，本例只分析--config-file的解析过程，--config-dir的解析过程基本一致，区别仅为通过搜索目录下的.conf文件来定位config-file，本例不再进行分析 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-08 15:40:16 "},"common_lib/oslo_config/neutron_conf.html":{"url":"common_lib/oslo_config/neutron_conf.html","title":"neutron与cfg.CONF","keywords":"","body":"neutron配置文件 neutron启动中两个重要的配置文件，分别为 neutron.conf ml2_conf.ini 其中定义了若干个组，比如 neutron.conf中的DEFAULT，nova，databas组等 ml2_conf.ini中的ml2，ml2_type_vlan，ovs组等 这些组中都有若干个参数，这里不一一解释，后面章节的解析中会逐渐将参数的解析结合业务功能纳入进来 neutron 注册参数 neutron代码中注册参数是通过不同的模块代码进行注册的，比如ml2相关的参数，是通过neutron/plugins/ml2/config.py文件进行注册的，大致如下 ml2_opts = [ cfg.ListOpt('type_drivers', default=['local', 'flat', 'vlan', 'gre', 'vxlan', 'geneve'], help=_(\"List of network type driver entrypoints to be loaded \" \"from the neutron.ml2.type_drivers namespace.\")), cfg.ListOpt('tenant_network_types', default=['local'], help=_(\"Ordered list of network_types to allocate as tenant \" \"networks. The default value 'local' is useful for \" \"single-box testing but provides no connectivity \" \"between hosts.\")), # ... ] cfg.CONF.register_opts(ml2_opts, \"ml2\") 这里定义了一组参数，注册的group名为ml2 其他部分组的注册位置： DEFAULT：neutron/conf/common.py nova：neutron/conf/common.py ovs:neutron/conf/plugins/ml2/drivers/ovs_conf.py securitygroup:neutron/conf/agent/securitygroups_rpc.py ml2_type_vlan、ml2_type_vxlan、ml2_type_geneve、ml2_type_flat、ml2_type_gre：neutron/conf/plugins/ml2/drivers/driver_type.py 以上列举了一部分重要的组，还有一些组是通过插件的形式或者调用库的形式注册进来的，比如keystone_authtoken组是通过import keystone库进行注册，ovn组是通过mechanism plugin方式进行注册 neutron传递命令行流程 graph TD A(neutron.cmd.eventlet.server.main)-->B(neutron.server.boot_server) B-->C(neutron/common/config.init) def init(args, **kwargs): cfg.CONF(args=args, project='neutron', version='%%(prog)s %s' % version.version_info.release_string(), **kwargs) args = sys.argv[1:] By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-08 18:14:56 "},"common_lib/oslo_service/define.html":{"url":"common_lib/oslo_service/define.html","title":"简介","keywords":"","body":" oslo.service provides a framework for defining new long-running services using the patterns established by other OpenStack applications. It also includes utilities long-running applications might need for working with SSL or WSGI, performing periodic operations, interacting with systemd, etc. 以上这段是官网的定义，意为通过oslo.service提供了一个框架来建立一个长期运行的服务，供openstack其他应用进行调用。它还包括建立对于需要SSL或者WSGI，或需要定期操作，或需要与systemd进行通信等等的长期运行的应用程序 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-09 17:00:08 "},"common_lib/oslo_service/wsgi_eventlet.html":{"url":"common_lib/oslo_service/wsgi_eventlet.html","title":"eventlet.wsgi","keywords":"","body":"什么是WSGI Web服务器网关接口（Web Server Gateway Interface，缩写为WSGI）是为Python语言定义的Web服务器和Web应用程序或框架之间的一种简单而通用的接口。 WSGI不是服务器，python 模块，框架，API或者任何软件，只是一种规范，描述web server如何与web application通信的规范。server和application的规范在PEP 3333中有具体描述。要实现WSGI协议，必须同时实现web server和web application WSGI协议主要包括server和application两部分： WSGI server：负责从客户端接收请求，将request转发给application，将application返回的response返回给客户端 WSGI application：接收由server转发的request，处理请求，并将处理结果返回给server。application中可以包括多个栈式的中间件(middlewares)，这些中间件需要同时实现server与application，因此可以在WSGI服务器与WSGI应用之间起调节作用：对服务器来说，中间件扮演应用程序，对应用程序来说，中间件扮演服务器 oslo-service与eventlet oslo-service用到了eventlet中的wsgi模块，相当于oslo-service是对eventlet.wsgi的一个封装 eventlet 的 wsgi 模块提供了一种启动事件驱动的WSGI服务器的简洁手段，可以将其作为某个应用的嵌入web服务器，或作为成熟的web服务器 eventlet.wsgi 例子 本节通过一个简单的例子来演示eventlet.wsgi 要启动一个 wsgi 服务器，只需要创建一个套接字，然后用它调用 eventlet.wsgi.server() 就可以 from eventlet import wsgi import eventlet def hello_world(env, start_response): start_response('200 OK', [('Content-Type', 'text/plain')]) return ['Hello, World!\\r\\n'] sock = eventlet.listen(('', 8090)) wsgi.server(sock=sock, site=hello_world) 这个简单的例子包含了WSGI协议的两个部分，分别为 创建了一个socket，监听8090端口 通过调用wsgi.server创建了一个wsgi service 注册了一个WSGI application，处理函数为hello_world 运行一下 # python eventlst_wsgi.py (56124) wsgi starting up on http://0.0.0.0:8090 通过客户端访问 # curl http://127.0.0.1:8090 Hello, World! 访问成功并且通过hello_world函数处理后返回了结果 本节旨在通过简单的例子来演示一下eventlet.wsgi的用法，在后面讲解oslo-service时对eventlet.wsgi有一个概念，关于eventlet.wsgi更详细的用法请大家通过网络自行学习，由于不是本书主要介绍的内容，暂不进行更深入的讲解 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-10 17:58:24 "},"common_lib/oslo_service/pastedeploy.html":{"url":"common_lib/oslo_service/pastedeploy.html","title":"PasteDeploy","keywords":"","body":"Paste Deploy 对于Paste Deploy的介绍，官方介绍如下 Paste Deployment is a system for finding and configuring WSGI applications and servers. For WSGI application consumers it provides a single, simple function (loadapp) for loading a WSGI application from a configuration file or a Python Egg. For WSGI application providers it only asks for a single, simple entry point to your application, so that application users don’t need to be exposed to the implementation details of your application. Paste Deployment是一个用于查找和配置WSGI应用程序和服务器的系统。对于WSGI应用程序使用者，它提供了一个简单的函数（loadapp），用于从配置文件或Python Egg加载WSGI应用程序。对于WSGI应用程序提供程序，它只要求为您的应用程序提供一个简单的入口点，这样应用程序用户就不需要了解应用程序的实现细节。 上一节我们介绍了wsgi服务，其中提到了wsgi service的两个重要步骤，在这里也有提及，为通过PasteDeploy可以做到： 1.配置WSGI服务 2.通过配置文件加载WSGI application 3.WSGI application只需要提供一个简单的入口点 对于以上几点，我们会在后面的讲解中进行说明 安装PasteDeploy # sudo pip install PasteDeploy 例子 本节通过一个简单的例子来演示PasteDeploy的用法，其中wsgi服务使用上节讲解的eventlet.wsgi 编写配置文件 pastedeploylab.ini [DEFAULT] key1=value1 key2=value2 key3=values [composite:pdl] use=egg:Paste#urlmap /:root /calc:calc [pipeline:root] pipeline = logrequest showversion [pipeline:calc] pipeline = logrequest calculator [filter:logrequest] username = root password = root123 paste.filter_factory = pastedeploylab:LogFilter.factory [app:showversion] version = 1.0.0 paste.app_factory = pastedeploylab:ShowVersion.factory [app:calculator] description = This is an \"+-*/\" Calculator paste.app_factory = pastedeploylab:Calculator.factory [DEFAULT]段定义了一些全局变量 [composite:pdl]定义了一个名为pdl的分发器 直接访问ip:port的请求分发给root过滤器 访问ip:port/calc的请求分发给calc过滤器 [pipeline:root]定义了root过滤器，转发请求给logrequest和showversion [pipeline:calc]定义了calc过滤器，转发请求给logrequest和calculator [filter:logrequest]定义了logrequest过滤器，调用的代码为pastedeploylab.py中的LogFilter.factory函数 [app:showversion]定义了一个名为showversion的app，调用代码为pastedeploylab.py中的ShowVersion.factory函数 [app:calculator]定义了一个名为calculator的app，调用代码为pastedeploylab.py中的Calculator.factory函数 编写py文件 pastedeploylab.py import os from webob import Request from webob import Response from paste.deploy import loadapp from eventlet import wsgi import eventlet #Filter class LogFilter(): def __init__(self,app): self.app = app pass def __call__(self,environ,start_response): print \"filter:LogFilter is called.\" return self.app(environ,start_response) @classmethod def factory(cls, global_conf, **kwargs): print \"in LogFilter.factory\", global_conf, kwargs return LogFilter class ShowVersion(): def __init__(self): pass def __call__(self,environ,start_response): start_response(\"200 OK\",[(\"Content-type\", \"text/plain\")]) return [\"Paste Deploy LAB: Version = 1.0.0\",] @classmethod def factory(cls,global_conf,**kwargs): print \"in ShowVersion.factory\", global_conf, kwargs return ShowVersion() class Calculator(): def __init__(self): pass def __call__(self,environ,start_response): req = Request(environ) res = Response() res.status = \"200 OK\" res.content_type = \"text/plain\" # get operands operator = req.GET.get(\"operator\", None) operand1 = req.GET.get(\"operand1\", None) operand2 = req.GET.get(\"operand2\", None) print req.GET opnd1 = int(operand1) opnd2 = int(operand2) if operator == u'plus': opnd1 = opnd1 + opnd2 elif operator == u'minus': opnd1 = opnd1 - opnd2 elif operator == u'star': opnd1 = opnd1 * opnd2 elif operator == u'slash': opnd1 = opnd1 / opnd2 res.body = \"%s /nRESULT= %d\" % (str(req.GET) , opnd1) return res(environ,start_response) @classmethod def factory(cls,global_conf,**kwargs): print \"in Calculator.factory\", global_conf, kwargs return Calculator() if __name__ == '__main__': configfile=\"pastedeploylab.ini\" appname=\"pdl\" wsgi_app = loadapp(\"config:%s\" % os.path.abspath(configfile), appname) wsgi.server(eventlet.listen(('', 8090)), wsgi_app) main函数中指定加载pastedeploylab.ini配置文件，并load pdl这个app，对应配置文件中的[composite:pdl]分发器 使用eventlet.wsgi启动一个0.0.0.0:8090端口的http服务 每个app或者filter的factory函数，global_conf参数为全局变量字典，**kwargs为ini文件中定义的此app段中的局部变量字典 在ShowVersion.call中，调用start_response返回消息头，return返回消息体 在Calculator.call中，先构造一个Response对象，在其中填充消息头和消息体，然后一起返回 运行 # python pastedeploylab.py 调用 # curl http://127.0.0.1:8080 Paste Deploy LAB: Version = 1.0.0 # curl \"http://127.0.0.1:8090/calc?operator=plus&operand1=12&operand2=23\" GET([(u'operator', u'plus'), (u'operand1', u'12'), (u'operand2', u'23')]) /nRESULT= 35 通过本章，了解了如何通过PasteDeploy加载配置文件，将wsgi server和wsgi application进行解耦合，并通过其中的middleware机制对请求进行中间处理，后面在讲解neutron的keystone 校验时，会着重讲解middleware在neutron中的应用 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-09 16:53:19 "},"common_lib/oslo_service/oslo_service.html":{"url":"common_lib/oslo_service/oslo_service.html","title":"oslo-service使用","keywords":"","body":"oslo service 上两节讲解了oslo-service用到的两项关键性的技术，分别为wsgi和PasteDeploy，oslo-service可以理解为将对他们进行的封装，使用oslo-service，你可以快速搭建出来一套通过配置文件将server和application解耦合的restful api框架 本节将着重讲解oslo-service的使用 安装 # pip install oslo.service 例子代码 我们同样使用pastedeploy章节的例子来讲解，只不过创建wsgi server的部分由eventlet.wsgi换成oslo-service 创建oslo-config配置文件 oslo-service需要用到oslo-config来读取配置文件，我们先要创建一个配置文件 config.cfg [DEFAULT] api_paste_config=./service.ini 这里只定义了一个参数，为pastedeploy.ini的路径 编写pastedeploy配置文件 service.ini [DEFAULT] key1=value1 key2=value2 key3=values [composite:pdl] use=egg:Paste#urlmap /:root /calc:calc [pipeline:root] pipeline = logrequest showversion [pipeline:calc] pipeline = logrequest calculator [filter:logrequest] username = root password = root123 paste.filter_factory = service:LogFilter.factory [app:showversion] version = 1.0.0 paste.app_factory = service:ShowVersion.factory [app:calculator] description = This is an \"+-*/\" Calculator paste.app_factory = service:Calculator.factory 在上一节已经对参数进行了讲解，本节不在进行讲解，详见上一节 编写py文件 service.py from oslo_config import cfg import oslo_service.wsgi from webob import Request from webob import Response import sys from oslo_service import service #Filter class LogFilter(): def __init__(self,app): self.app = app pass def __call__(self,environ,start_response): print \"filter:LogFilter is called.\" return self.app(environ,start_response) @classmethod def factory(cls, global_conf, **kwargs): print \"in LogFilter.factory\", global_conf, kwargs return LogFilter class ShowVersion(): def __init__(self): pass def __call__(self,environ,start_response): start_response(\"200 OK\",[(\"Content-type\", \"text/plain\")]) return [\"Paste Deploy LAB: Version = 1.0.0\",] @classmethod def factory(cls,global_conf,**kwargs): print \"in ShowVersion.factory\", global_conf, kwargs return ShowVersion() class Calculator(): def __init__(self): pass def __call__(self,environ,start_response): req = Request(environ) res = Response() res.status = \"200 OK\" res.content_type = \"text/plain\" # get operands operator = req.GET.get(\"operator\", None) operand1 = req.GET.get(\"operand1\", None) operand2 = req.GET.get(\"operand2\", None) print req.GET opnd1 = int(operand1) opnd2 = int(operand2) if operator == u'plus': opnd1 = opnd1 + opnd2 elif operator == u'minus': opnd1 = opnd1 - opnd2 elif operator == u'star': opnd1 = opnd1 * opnd2 elif operator == u'slash': opnd1 = opnd1 / opnd2 res.body = \"%s /nRESULT= %d\" % (str(req.GET) , opnd1) return res(environ,start_response) @classmethod def factory(cls,global_conf,**kwargs): print \"in Calculator.factory\", global_conf, kwargs return Calculator() if __name__ == '__main__': cfg.CONF(args=sys.argv[1:]) loader = oslo_service.wsgi.Loader(cfg.CONF) app = loader.load_app('pdl') server = oslo_service.wsgi.Server(conf=cfg.CONF,name=\"pdl\",app=app,host='127.0.0.1',port=8090) service_launcher = service.ServiceLauncher(cfg.CONF) service_launcher.launch_service(server) service_launcher.wait() 与pastedeploy章节的例子比起来，这里只有main函数做了改动，改动如下 application通过oslo_service.wsgi.Loader来创建 通过oslo_service.wsgi.Server创建服务 通过service.ServiceLauncher启动服务 run # python service.py --config-file ./config.cfg 客户端访问 # curl http://127.0.0.1:8090 Paste Deploy LAB: Version = 1.0.0 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-10 16:52:20 "},"common_lib/oslo_service/service_usage.html":{"url":"common_lib/oslo_service/service_usage.html","title":"oslo-service其他用法","keywords":"","body":"通过上一节的例子已经讲解了如果通过oslo-service构建一个resetful service 本节对其扩展用法进行一下说明 创建service的方式 创建单个服务进程 上一节的例子即创建了单个服务线程，是通过如下的方式进行创建的 from oslo_config import cfg from oslo_service import service CONF = cfg.CONF service_launcher = service.ServiceLauncher(CONF) service_launcher.launch_service(service.Service()) 这样创建出来的wsgi server只有单个进程进行处理 创建多个服务进程 from oslo_config import cfg from oslo_service import service CONF = cfg.CONF process_launcher = service.ProcessLauncher(CONF, wait_interval=1.0) process_launcher.launch_service(service.Service(), workers=2) 创建launcher时选择ProcessLauncher并且在调用launch_service时通过workers参数配置进程数量 简单创建 以上两种创建方式可以再简化为如下方式 from oslo_config import cfg from oslo_service import service CONF = cfg.CONF launcher = service.launch(CONF, service, workers=2) 通过workers值来选择创建单进程还是多进程服务 通过backdoor访问后门进行调试 oslo-service预留了调试的后门，打开后门后，可以通过远程连接进去debug 默认oslo-service内置了5个调试命令分别如下 命令 作用 说明 fo 查找对象 查找server栈中的所有对象 pgt 打印greenthreads oslo-service内部的线程使用的是eventlet.greenthreads,此命令打印所有greenthread的堆栈信息 pnt 打印native thread 打印python原生线程的堆栈信息 exit 退出 不能使用，仅仅打印一行无用信息 quit 退出 不能使用，仅仅打印一行无用信息 对于其代码实现原理，可以查看后续章节的源码解析 我们同样是利用上一节的service.py的代码进行演示 添加一些变量和打印 class ShowVersion(): def __init__(self): self.name = 'lucy' def __call__(self,environ,start_response): start_response(\"200 OK\",[(\"Content-type\", \"text/plain\")]) return [\"Paste Deploy LAB: Version = 1.0.0\",' name is:' + self.name] 在ShowVersion中添加一个name属性，并且在收到resetful api调用时返回值中加上name 修改配置文件开启backdoor 编辑config.conf文件 [DEFAULT] backdoor_port = 1111 api_paste_config=./service.ini 添加backdoor_port属性，表示连接后门的端口 运行 # python service.py --config-file ./config.cfg backdoor server listening on 127.0.0.1:1111 先看一下当前的name # curl http://127.0.0.1:8090 Paste Deploy LAB: Version = 1.0.0 name is:lucy 打印出来开启了backdoor server，监听了127.0.0.1:1111端口 远端连接backdoor # telnet 127.0.0.1 1111 Python 2.7.16 (default, Apr 12 2019, 15:32:40) [GCC 4.2.1 Compatible Apple LLVM 10.0.1 (clang-1001.0.46.3)] on darwin Type \"help\", \"copyright\", \"credits\" or \"license\" for more information. (InteractiveConsole) >>> 获取变量 >>> from service import ShowVersion >>> obj = fo(ShowVersion) >>> obj [] fo是内置的获取对象的函数，这里我获取所有ShowVersion类的对象 返回的是一个list，看到获取到了一个对象，即通过PasteDeploy创建的对象 打印并修改变量 >>> obj[0].name 'lucy' >>> obj[0].name='kity' 打印当前值，为我们程序初始化时赋予的默认值'lucy' 修改这个值为'kity' 远程调用查看服务中的值是否真正修改 # curl http://127.0.0.1:8090 Paste Deploy LAB: Version = 1.0.0 name is:kity 可以看到server的name真的改成了'kity' 打印native thread信息 通过内置命令pnt打印native thread信息 >>> pnt() 4581979584 File \"/usr/local/lib/python2.7/site-packages/eventlet/backdoor.py\", line 58, in run console.interact() File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/code.py\", line 243, in interact more = self.push(line) File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/code.py\", line 265, in push more = self.runsource(source, self.filename) File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/code.py\", line 87, in runsource self.runcode(code) File \"/usr/local/Cellar/python@2/2.7.16/Frameworks/Python.framework/Versions/2.7/lib/python2.7/code.py\", line 103, in runcode exec code in self.locals File \"\", line 1, in File \"/usr/local/lib/python2.7/site-packages/oslo_service/eventlet_backdoor.py\", line 131, in _print_nativethreads traceback.print_stack(stack) 打印greenthread信息 通过内置命令pgt打印eventlet greenthread信息 >>> pgt() 0 File \"/usr/local/lib/python2.7/site-packages/eventlet/hubs/hub.py\", line 346, in run self.wait(sleep_time) File \"/usr/local/lib/python2.7/site-packages/eventlet/hubs/kqueue.py\", line 107, in wait readers.get(fileno, noop).cb(fileno) File \"/usr/local/lib/python2.7/site-packages/eventlet/backdoor.py\", line 66, in switch greenlets.greenlet.switch(self, *args, **kw) 1 File \"/usr/local/lib/python2.7/site-packages/eventlet/greenthread.py\", line 214, in main result = function(*args, **kwargs) ... 2 File \"/usr/local/lib/python2.7/site-packages/eventlet/greenthread.py\", line 214, in main result = function(*args, **kwargs) ... 3 File \"/usr/local/lib/python2.7/site-packages/eventlet/greenthread.py\", line 214, in main result = function(*args, **kwargs) ... 4 File \"/usr/local/lib/python2.7/site-packages/eventlet/backdoor.py\", line 58, in run console.interact() ... 5 File \"service.py\", line 75, in ... 可以看到有5个greenthread创建，并且把每个thread的当前堆栈都打印了出来，由于内容太多我进行了省略 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-10 17:20:36 "},"common_lib/oslo_service/code_parse.html":{"url":"common_lib/oslo_service/code_parse.html","title":"oslo-service源码解析","keywords":"","body":"源码解析 上节讲解oslo-service用法时提到，oslo-service是对eventlet.wsgi和PasteDeploy进行的封装，我们本章进行源码解析的前提条件，是以黑盒的方式看待eventlet.wsgi和PasteDeploy，通过讲解oslo-service对这两个库的封装和调用的方式来解析源码 对eventlet.wsgi的封装 eventlet.wsgi两个关键步骤 回头看一下eventlet.wsgi章节的代码，启动代码如下 from eventlet import wsgi import eventlet def hello_world(env, start_response): start_response('200 OK', [('Content-Type', 'text/plain')]) return ['Hello, World!\\r\\n'] sock = eventlet.listen(('', 8090)) wsgi.server(sock=sock, site=hello_world) 关键步骤只有两行代码，分别为 通过eventlet.listen创建监听socket 通过wsgi.server创建wsgi server oslo-service创建socket 在初始化oslo-service时，我们用到了如下代码创建了一个server server = oslo_service.wsgi.Server(conf=cfg.CONF,name=\"pdl\",app=app,host='127.0.0.1',port=8090) 在wsgi.Server类的init函数中，对socket进行了初始化 # oslo_service/wsgi.py import socket class Server(service.ServiceBase): def __init__(self, conf, name, app, host='0.0.0.0', port=0,socket_family=None): # ... if not socket_family or socket_family in [socket.AF_INET, socket.AF_INET6]: self.socket = self._get_socket(host, port, backlog) # ... def _get_socket(self, host, port, backlog): bind_addr = (host, port) info = socket.getaddrinfo(bind_addr[0], bind_addr[1], socket.AF_UNSPEC, socket.SOCK_STREAM)[0] family = info[0] bind_addr = info[-1] # ... sock = eventlet.listen(bind_addr, family, backlog=backlog) # ... return sock 初始化Server是，传入了host和port 通过调用_get_socket函数创建了socket oslo-service创建wsgi server 创建wsgi server用到了如下两个函数 service_launcher = service.ServiceLauncher(cfg.CONF) service_launcher.launch_service(server) 创建了一个ServiceLauncher类的launcher 调用launch_service函数启动服务 graph TD A(ServiceLauncher.launch_service)-->B(Services.add) B-->C(ThreadGroup.add_thread) C-->D(greenpool.GreenPool.spawn) gt = self.pool.spawn(callback, *args, **kwargs) 通过greenpool创建了一个线程，线程函数callback为Services.run_service,参数为上一步创建的wsgi.Server class Services(object): @staticmethod def run_service(service, done): service.start() 这里调用到了wsgi.Server的star函数 class Server(service.ServiceBase): def start(self): self.dup_socket = self.socket.dup() # ... wsgi_kwargs = { 'func': eventlet.wsgi.server, 'sock': self.dup_socket, 'site': self.app, 'protocol': self._protocol, 'custom_pool': self._pool, 'log': self._logger, 'log_format': self.conf.wsgi_log_format, 'debug': False, 'keepalive': self.conf.wsgi_keep_alive, 'socket_timeout': self.client_socket_timeout } # ... self._server = eventlet.spawn(**wsgi_kwargs) 先duplicate一份socket，为什么要做这一步，因为在使用ProcessLauncher时，需要这么做（关于ProcessLauncher的一些细节请看后续章节），原因如下 因为每个已打开的文件，在内核中都会用一个file结构体来表示，file结构体中有一个属性为f_count，表示当前文件的引用计数，如果调用close，引用计数会减一，如果引用计数变为0，则内核会释放此文件，达到真正的关闭文件 所以这里先dup，仅仅为如果有其他地方同样用到了此socket，先dup一下，让文件计数+1，则无论哪一方先关闭了socket，都不会让内核释放已打开的文件 利用eventlet.spawn创建一个green thread，其中线程体为eventlet.wsgi.server 注：简单说一下**wsgi_kwargs，免得有写对pyhton不是很熟的小伙伴看不懂这里，**+变量表示将字典展开，要求变量一定是字典，展开之后会变成多个属性，比如d={'name':'jack','age':10} 则**d会被展开为(name='jack',age=10),所以**wsgi_kwargs会直接变为eventlet.spawn的实参进行调用 对PasteDeploy的封装 回顾PasteDeploy的启动过程，可以总结为一下两个关键步骤 通过paste.deploy.loadapp函数加载配置文件，创建app 将app注册进wsgi server wsgi_app = loadapp(\"config:%s\" % os.path.abspath(configfile), appname) wsgi.server(eventlet.listen(('', 8090)), wsgi_app) 本节将针对这两个关键步骤进行分析 loadapp oslo-service中loadapp调用过程如下 cfg.CONF(args=sys.argv[1:]) loader = oslo_service.wsgi.Loader(cfg.CONF) app = loader.load_app('pdl') cfg.CONF初始化配置文件，相关详细讲解请查看oslo-config章节的教程 初始化Loader对象 # oslo_service/wsgi.py class Loader(object): def __init__(self, conf): conf.register_opts(_options.wsgi_opts) self.config_path = conf.api_paste_config # ... 初始化过程比较简单，首先注册了一下wsgi相关的参数，其中包括'api_paste_config'参数，这个参数也配置到了配置文件中，指向pastedeploy配置文件，然后保存了配置文件的路径 调用loader.load_app创建applicatioin # oslo_service/wsgi.py class Loader(object): def load_app(self, name): return deploy.loadapp(\"config:%s\" % self.config_path, name=name) 此处仅仅是对pastedeploy loadapp简单的封装 创建wsgi server 在server初始化时，传入了上一步load出的app，保存在server的self.app中 # oslo_service/wsgi.py class Server(service.ServiceBase): def __init__(self, conf, name, app, host='0.0.0.0', port=0,socket_family=None): # ... self.app = app # ... Server.start函数中，通过wsgi_kwargs的site参数，将app传递给了eventlet.wsgi.server class Server(service.ServiceBase): def start(self): self.dup_socket = self.socket.dup() # ... wsgi_kwargs = { 'func': eventlet.wsgi.server, 'sock': self.dup_socket, 'site': self.app, #... } # ... self._server = eventlet.spawn(**wsgi_kwargs) 小结 通过上一章的解析，将oslo-service如何封装pastedeploy和eventlet.wsgi进行了源码层面的分析 ProcessLauncher创建多进程 上一节我们讲解了ServiceLauncher的实现原理，本节着重讲解ProcessLauncher对于多进程的处理 直接看到ProcessLauncher.launch_service函数 class ProcessLauncher(object): def launch_service(self, service, workers=1): wrap = ServiceWrapper(service, workers) while self.running and len(wrap.children) 从launch_service的结构来看，其目的是不断的调用_start_child创建子进程，直到子进程的数量与我们期望的workers数量相等为止 _start_child函数是关键，我们来看一下这个函数 def _start_child(self, wrap): # ... pid = os.fork() if pid == 0: self.launcher = self._child_process(wrap.service) while True: self._child_process_handle_signal() # ...进入事件循环 os._exit(status) wrap.children.add(pid) self.children[pid] = wrap return pid 在_start_child中，先fork一个子进程，如果pid==0表示是子进程的进程空间，则调用_child_process launch service，并进入事件循环，如果是父进程空间，则加入wrap.children并返回 返回后的while循环会不断的判断wrap.children中的进程数是否已经达到目标值，否则会不断的调用_start_child创建子进程，知道达标 self._child_process功能即用Launcher启动服务,与ServiceLauncher启动过程一致 def _child_process(self, service): # ... launcher = Launcher(self.conf, restart_method=self.restart_method) launcher.launch_service(service) return launcher 对socket dup的说明 上一节提到了server.start时需要先dup socket，在上节说明了目标，目标是多个进程共享同一个socket的文件，但是当其中某个进程退出时调用socket.close,不会影响其他进程 本节在代码层面进行分析 socket初始化在fork之前，在server的init函数中 # oslo_service/wsgi.py import socket class Server(service.ServiceBase): def __init__(self, conf, name, app, host='0.0.0.0', port=0,socket_family=None): # ... if not socket_family or socket_family in [socket.AF_INET, socket.AF_INET6]: self.socket = self._get_socket(host, port, backlog) # ... 当调用到_start_child fork子进程后，两个进程空间共享了此socket 即在进程A,B，C中，尽管他们拥有了自己独有的对象栈空间，socket对象均有用独立的内存空间，但socket中的文件描述符一致 显示调用dup函数后，会创建不同的文件描述符指向同一个文件，使内核中此文件的引用计数+1，socket关闭时不会影响其他进程的socket By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-14 15:32:31 "},"common_lib/oslo_service/neutron_oslo_service.html":{"url":"common_lib/oslo_service/neutron_oslo_service.html","title":"neutron与oslo-service","keywords":"","body":"neutron与oslo-service 上面的章节进行了oslo-service用法和源码的解析，本章讲解在neutron中，是如何通过oslo-service创建resetful api server的 neutron Server neutron中定义了一个wsgi server类，位置在neutron/wsgi.py # neutron/wsgi.py class Server(object): def __init__(self, name, num_threads=None, disable_ssl=False): # ... self.pool = eventlet.GreenPool(1) self.name = name # ... 初始化时传入了一些参数，包括Server name表示服务名，num_threads表示启动线程的个数，disable_ssl表示其否启用ssl等 再看它对oslo-service调用的封装 def start(self, application, port, host='0.0.0.0', workers=0): self._host = host self._port = port backlog = CONF.backlog self._socket = self._get_socket(self._host, self._port, backlog=backlog) self._launch(application, workers) 首先通过_get_socket创建eventlet监听的socket def _get_socket(self, host, port, backlog): bind_addr = (host, port) # ... sock = eventlet.listen(bind_addr, backlog=backlog, family=family) # ... return sock 然后通过oslo-service的ProcessLaunch启动服务 from oslo_service import service as common_service def _launch(self, application, workers=0): service = WorkerService(self, application, self.disable_ssl, workers) # ... self._server = common_service.ProcessLauncher(cfg.CONF, wait_interval=1.0) self._server.launch_service(service, workers=service.worker_process_count) 关于WorkerService会在下一节进行解析，这里可以先认为是一个可launch的wsgi service 通过创建ProcessLauncher并调用launch_service的方式启动wsgi服务，这一步在之前章节有讲解，这里不再进行介绍 neutron WorkerService 在oslo-service章节中，我们讲到了创建server是这样创建的 server = oslo_service.wsgi.Server(conf=cfg.CONF,name=\"pdl\",app=app,host='127.0.0.1',port=8090) oslo_service.wsgi.Server是oslo-service框架的一个内置类，它继承自oslo_service.service.ServiceBase oslo_service.service.ServiceBase是一个抽象类，定义了四个抽象方法，分别为start，stop，wait，reset 如果内置的Server类不能满足用户的需要，可以通过实现ServiceBase抽象接口的方法来实现自己的Service类 在neutron中，即实现了自己的Service类，他的继承层次如下 from oslo_service import service class NeutronWorker(service.ServiceBase): pass class WorkerService(NeutronWorker): pass 我们这里着重讲解一下WorkerService这个类 # neutron/wsgi.py class WorkerService(neutron_worker.NeutronWorker): def __init__(self, service, application, disable_ssl=False, worker_process_count=0): super(WorkerService, self).__init__(worker_process_count) self._service = service self._application = application self._disable_ssl = disable_ssl self._server = None init函数传入了启动service必要的一些参数，包括 service为上一节的Server对象，后面会用到其中保存的socket对象 application 为通过pastedeploy加载的app 在上面的章节知道了，service启动会调用到其start函数 class WorkerService(neutron_worker.NeutronWorker): def start(self): # ... dup_sock = self._service._socket.dup() self._server = self._service.pool.spawn(self._service._run, self._application, dup_sock) 照例先dup一下socket，原因请看上一章的讲解 然后调用了self._service._run，这里的self._service为上一节介绍的neutron.wsgi.Server类，我们看他的_run函数 class Server(object): def _run(self, application, socket): eventlet.wsgi.server(socket, application, max_size=self.num_threads, log=LOG, keepalive=CONF.wsgi_keep_alive, socket_timeout=self.client_socket_timeout) 看到这个调用已经非常熟悉了，就是eventlet.wsgi章节讲解的server 小结：Neutron并没有直接调用oslo-service内置的server类，而是自己实现了一个简化版的server，直接封装了eventlet.wsgi，结合oslo-service章节对eventlet封装的分析，这段代码就很容易理解了 neutron wsgi service neutron中定义了一个WsgiService类，这个类的定义如下 # neutron/service.py class WsgiService(object): def __init__(self, app_name): self.app_name = app_name self.wsgi_app = None def start(self): self.wsgi_app = _run_wsgi(self.app_name) def wait(self): self.wsgi_app.wait() 这个类的init函数中初始化了两个变量，一个为app_name，一个为wsgi_app，通过这两个变量我们也能够猜测到，这个类就是一个将wsgi和app进行包装的类 他的start函数中调用了一个本地私有函数_run_wsgi def _run_wsgi(app_name): app = config.load_paste_app(app_name) run_wsgi_app(app) _run_wsgi中，load了pastedeploy的app，这里不再做详细展开 然后调用了run_wsgi_app函数 def run_wsgi_app(app): server = wsgi.Server(\"Neutron\") server.start(app, cfg.CONF.bind_port, cfg.CONF.bind_host, workers=_get_api_workers()) return server wsgi.Server即我们上面降到的Server类，这里进行了初始化 然后调用了server的start函数启动wsgi service 流程图 从neutron启动到wsgi server启动成功，流程图是这样的 graph TD A(neutron.cmd.eventlet.main) --> B(neutron.server.boot_server) B --> C(neutron.cmd.eventlet._main_neutron_server) C --> D(neutron.server.wsgi_eventlet.eventlet_wsgi_server) D --> E(neutron.service.serve_wsgi) E --> F(neutron.service.NeutronApiService.start) F --> H(neutron.service._run_wsgi) H --> I(neutron.service.run_wsgi_app) I --> K(neutron.wsgi.Server.start) K --> L(neutron.wsgi.Server._launch) L --> N(oslo_service.service.ProcessLauncher.launch_service) By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-13 18:27:31 "},"common_lib/oslo_messaging/define.html":{"url":"common_lib/oslo_messaging/define.html","title":"简介","keywords":"","body":"oslo-messaging是openstack官方的一个重要的rpc库，他利用ampq协议构建了一套远程过程调用的框架 使用oslo-messaging库，我们可以很快构建出来一套基于rpc调用的服务 RPC 远程过程调用（英语：Remote Procedure Call，缩写为 RPC）是一个计算机通信协议。该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用编程。 与远程过程调用相对的是本地过程调用，通俗的来讲，同一个进程中的调用，我们称为本地调用，方法为直接调用全局函数或者类函数，对于编译运行的语言，这种调用在程序编译期就已经明确了所调用目标的函数指针，以及函数的方法与过程 而远程过程调用，则是通过构建在tcp协议以上的协议，如amqp协议，http协议等通过网络传递调用信息到远端，由远端程序响应后执行相应的操作，返回对应的结果的一种调用方法 使用rpc，你可以像调用本地函数一样调用远端的函数，在分布式，云计算，微服务等领域具有不可替代的作用 AMQP协议 AMQP，即Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计。基于此协议的客户端与消息中间件可传递消息，并不受客户端/中间件不同产品，不同的开发语言等条件的限制。 其设计目标是对于消息的排序、路由（包括点对点和订阅-发布）、保持可靠性、保证安全性[1]。高级消息队列协议保证了由不同提供商发行的客户端之间的互操作性。 RabbitMQ 介绍 RabbitMQ是一个在AMQP（Advanced Message Queuing Protocol ）基础上实现的，可复用的企业消息系统。它可以用于大型软件系统各个模块之间的高效通信，支持高并发，支持可扩展。 RabbitMQ is a message broker: it accepts and forwards messages. You can think about it as a post office: when you put the mail that you want posting in a post box, you can be sure that Mr. or Ms. Mailperson will eventually deliver the mail to your recipient. In this analogy, RabbitMQ is a post box, a post office and a postman. 以上这段是官网对于rabbitmq形象的比喻，大致意为RabbitMQ是一个消息代理者，它接收消息并且转发消息。你可以将其视为邮局：你投递邮件到邮箱时，你能确定邮递员最终一定会将邮件送达到你的收件人。在这个类比中，RabbitMQ即是邮箱，又是邮局，又是邮递员 RabbitMQ中重要的概念 Broker: 指消息队列所在服务器实体 Exchange：消息交换机，用于路由消息（消息发给exchange，exchange发给对应的queue） Queue：消息队列，消息的载体，接收Exchange发送过来的消息 Routing Key：路由关键字，消息根据路由关键字进行转发，类似于map中的key，根据key找到value（消息队列） producer：消息生产者，即发送消息的一放，创建消息，发送消息 consumer：消息消费者，即接收消息的一放 channel：消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务。 Exchange类型 exchange有四种类型，分别为fanout,direct,topic,header，其中常用的三种为fanout,direct,topic，而header在实际应用中较少出现，所以这里只介绍常用的三种类型 Direct Exchange 这个模式下的Exchange，需要binding key绑定queue（可以绑定一个或多个queue），收到消息时，exchange会根据routing key转发到与其绑定的所有queue中，如果没有绑定的queue，则消息丢弃 Binding_key对queue的绑定可以一对一，也可以一对多，看以下两个例子 一对一绑定 在这个例子中，Exchange x上三个binding key:orange,black,green 均只绑定了一个queue 当x收到带有routing key为orange的消息时，将消息路由到Q1上 当x收到带有routing key为black或green的消息时，将消息路由到Q2上 一对多绑定 在这个例子中，Exchange x上一个binding key：black 绑定了两个queue 当x收到带有routing key为black的消息时，将消息投递到Q1和Q2上 Fanout Exchange 这种类型的Exchange不需要binding_key与queue的绑定，exchange会将收到的消息广播到每一个queue中 在这种模式下，生产值只需要产生消息并发送到exchange，则每个与此exchange绑定的queue都会收到消息，实现一个消息被多个消费者获取的目的 Topic Exchange 这种模式与direct模式有一些类似，均为通过key进行消息路由，但是这种key的匹配支持模糊匹配，即可以通过过滤routing key中的某些关键字来进行路由 匹配规则如下： *只能替换匹配一个单词 能替换匹配0到多个单词 在这个例子中，我们要发送一些描述动物的消息，这些被发送的消息的routing_key 由三个单词（两个\".\"）组成， \"..\". \".orange.\"绑定Q1 （所有三个单词的，中间单词是“orange”的消息都会发送到Q1） \"..rabbit\" 和\"lazy.#\".绑定Q2（三个单词的以rabbit结尾的消息和以lazy开头的多个单词都会发送到Q2） \"quick.orange.rabbit\" 发送到Q1和Q2 \"lazy.orange.elephant\" 发送到Q1和Q2 \"quick.orange.fox\" 发送到Q1 \"lazy.brown.fox\" 发送到Q2 \"lazy.pink.rabbit\" 发送到Q2（匹配两个binding_key,但是这两个bindling_key 都绑定的是Q2） \"quick.brown.fox\" 不匹配，这条消息会被丢弃 特殊情况： 一个单词:\"orange\",不匹配被丢弃 四个单词:\"quick.orange.male.rabbit\",不匹配被丢弃 \"lazy.orange.male.rabbit\"匹配\"lazy.#\",发送到Q2 当一个queue用\"#\"绑定时，将会收到所有的消息,如果不考虑routing_key基本和 fanout exchange一样 当queue既不用\"*\" 也不用\"#\"绑定时，那topic exchange基本和direct一样 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-05-20 16:51:16 "},"common_lib/oslo_messaging/kombu.html":{"url":"common_lib/oslo_messaging/kombu.html","title":"kombu","keywords":"","body":"上一章介绍了rabbitmq的概念，本章介绍一个python实现的amqp库kumbo 之所以要介绍kumbo，是因为在oslo-messaging中，kombu是openstack官方实现的amqp driver，其他的driver还有ZeroMQ,kafka,pika等 通过本章的学习，你将知道如何使用kumbo来连接rabbitmq，并在rabbitmq上创建exchange与queue，生产消息以及消费消息 几个重要步骤 我们在上一章讲解rabbitmq时，讲解了一些重要的概念，其中包括connection,exchange,queue,producer,consumer等 本章通过代码实践，将这些概念穿插起来，让读者能够通过真实的例子了解到这些概念的作用 通过总结，consumer端和producer端的步骤如下 consumer端步骤 定义connection 定义exchange 定义queue，绑定exchange与routing_key 定义consumer，绑定queue与回调函数 启动服务，处理回调 producer端步骤 定义connection 定义exchange 定义producer 通过producer向exchange发送消息 代码实例 本节通过代码实例来讲解kombu的用法，代码实例按照三种exchange分别举一个例子 direct exchange direct exchange根据确定的routing_key进行消息路由 consumer recver.py import sys from kombu import Exchange, Queue,Consumer from kombu import Connection conn = Connection('amqp://guest:guest@192.168.184.128:5672//') task_exchange = Exchange('kombu_test', type='direct') task_queues = [] severity = sys.argv[1] if not severity: sys.stderr.write(\"Usage: %s [info] [warning] [error]\\n\" % sys.argv[0]) sys.exit(1) q = Queue(severity, task_exchange, channel=conn.channel(),routing_key=severity) q.declare() def _callback( body, message): print(\" [x] %r:%r\" % (message.delivery_info['routing_key'], body)) message.ack() consumer = Consumer(conn.channel(),queues=[q],accept=['pickle', 'json'],callbacks=[_callback]) consumer.consume() while True: conn.drain_events() producer sender.py import sys from kombu.pools import producers from kombu import Exchange, Queue from kombu import Connection task_exchange = Exchange('kombu_test', type='direct') connection = Connection('amqp://guest:guest@192.168.184.128:5672//') severity = sys.argv[1] if len(sys.argv) > 1 else 'info' message = ' '.join(sys.argv[2:]) or 'Hello World!' with producers[connection].acquire(block=True) as producer: producer.publish(message, serializer='pickle', compression='bzip2', exchange=task_exchange, declare=[task_exchange], routing_key=severity) print(\" [x] Sent %r:%r\" % (severity, message)) run consumer python recver.py key1 producer python sender.py key1 hello world! consumer收到消息 python recver.py key1 [x] u'key1':'hello world!' fanout exchange consumer recver.py from kombu import Exchange, Queue from kombu import Connection from kombu.mixins import ConsumerMixin import uuid task_exchange = Exchange('kombu_test_fanout', type='fanout') task_queues = [Queue(str(uuid.uuid4()), task_exchange)] class Worker(ConsumerMixin): def __init__(self, connection): self.connection = connection def get_consumers(self, Consumer, channel): return [Consumer(queues=task_queues, accept=['pickle', 'json'], callbacks=[self.process_task])] def process_task(self, body, message): print(\" [x] %r:%r\" % (message.delivery_info['routing_key'], body)) message.ack() with Connection('amqp://guest:guest@192.168.184.128:5672//') as conn: try: worker = Worker(conn) worker.run() except KeyboardInterrupt: print('bye bye') producer sender.py import sys from kombu.pools import producers from kombu import Exchange, Queue from kombu import Connection task_exchange = Exchange('kombu_test_fanout', type='fanout') connection = Connection('amqp://guest:guest@192.168.184.128:5672//') message = ' '.join(sys.argv[1:]) or 'Hello World!' with producers[connection].acquire(block=True) as producer: producer.publish(message, serializer='pickle', compression='bzip2', exchange=task_exchange, declare=[task_exchange]) print(\" [x] Sent %r\" % ( message)) run 启动两个consumer python recver.py 启动一个producer python sender.py how are you [x] Sent 'how are you' 两个consumer均收到数据 # python recver.py [x] u'key1':'how are you' # python recver.py [x] u'key1':'how are you' topic exchange consumer recver.py import sys from kombu import Exchange, Queue from kombu import Connection from kombu.mixins import ConsumerMixin task_exchange = Exchange('kombu_test_topic', type='topic') task_queues = [] severities = sys.argv[1:] if not severities: sys.stderr.write(\"Usage: %s [info] [warning] [error]\\n\" % sys.argv[0]) sys.exit(1) for severity in severities: task_queues.append(Queue(severity, task_exchange, routing_key=severity)) class Worker(ConsumerMixin): def __init__(self, connection): self.connection = connection def get_consumers(self, Consumer, channel): return [Consumer(queues=task_queues, accept=['pickle', 'json'], callbacks=[self.process_task])] def process_task(self, body, message): print(\" [x] %r:%r\" % (message.delivery_info['routing_key'], body)) message.ack() with Connection('amqp://guest:guest@192.168.184.128:5672//') as conn: try: worker = Worker(conn) worker.run() except KeyboardInterrupt: print('bye bye') producer sender.py import sys from kombu.pools import producers from kombu import Exchange, Queue from kombu import Connection task_exchange = Exchange('kombu_test_topic', type='topic') connection = Connection('amqp://guest:guest@192.168.184.128:5672//') severity = sys.argv[1] if len(sys.argv) > 1 else 'info' message = ' '.join(sys.argv[2:]) or 'Hello World!' with producers[connection].acquire(block=True) as producer: producer.publish(message, serializer='pickle', compression='bzip2', exchange=task_exchange, declare=[task_exchange], routing_key=severity) print(\" [x] Sent %r:%r\" % (severity, message)) run recver1监听green.* # python recver.py \"green.*\" recver2监听#.dog # python recver.py \"#.dog\" sender发送 以green.dog为key发送 python sender.py green.dog this is tom [x] Sent 'green.dog':'this is tom' 两个都能收到 以blue.dog为key发送 只有recver2能收到 3.以old.green.dog发送 只有recver2能收到 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-18 14:38:38 "},"common_lib/oslo_messaging/oslo_message_usage.html":{"url":"common_lib/oslo_messaging/oslo_message_usage.html","title":"oslo-message使用","keywords":"","body":"上面的章节我们讲解了rpc的概念，以及如何使用rabbitmq来实现rpc的，rabbitmq通过一些列的抽象，定义出来了如exchange，queue，routing_key等模型来承载rpc消息，以及通过exchange的不同类型来定义了消息分发的模式 在本章中，我们来学习openstack封装的oslo-message，oslo-message是一个rpc远程调用库，它定义了一套新的概念来描述rpc调用，并通过插件的形式来加载后端驱动，如默认的RabbitDriver，还有其他的驱动如zmp、amqp、kafka、pika等driver，这些driver的作用即将oslo-message定义的概念与后端通信框架相耦合，启动起承转合的作用，如默认的RabbitDriver驱动，即通过kombu来进行amqp通信，如kafka driver是通过kafka进行通信 oslo-message相比amqp更简洁，它抛弃掉了amqp许多复杂的概念，使得使用oslo-message变得更简单，同时oslo-message定义的endpoint概念，将message调用封装为对象调用，使用者可以像定义类一样来定义msg调用，在从面向对象思想来看，他比纯rabbitmq的传递字符串模式又进步了不少 oslo-message安装 pip install oslo-message oslo-message例子 我们以一个get_version的例子来开启oslo-message的学习 config文件 config文件采用的同样是openstack家的oslo-config # vim config.cfg [DEFAULT] transport_url = rabbit://guest:guest@192.168.184.128:5672 这个config文件定义了transport的信息 格式为 驱动类型://用户名:密码@服务端IP:端口 这里默认使用rabbit驱动，rabbit驱动的后端实现为kombu guest:guest@192.168.184.128:5672是rabbitmq服务端的信息 server端 # vim server.py import sys from oslo_config import cfg import oslo_messaging import time class GetVersion(object): def get_version(self,ctx,arg): print \"------ GetVersion.get_version arg:%s--------\"%arg return \"version 1.0.0\" class TestEndpoint(object): def test(self, ctx, arg): print \"------ TestEndpoint.test --------\" return arg cfg.CONF(sys.argv[1:]) transport = oslo_messaging.get_transport(cfg.CONF) target = oslo_messaging.Target(topic='test', server='server1') endpoints= [ GetVersion(), TestEndpoint(), ] server = oslo_messaging.get_rpc_server(transport, target, endpoints, executor='blocking') try: server.start() while True: time.sleep(1) except KeyboardInterrupt: print(\"Stopping server\") server.stop() server.wait() 这里为了体现endpoints的定义规则，定义了两个函数，一个get_version一个test client端 # vim client.py import sys from oslo_config import cfg import oslo_messaging as messaging cfg.CONF(sys.argv[1:]) transport= messaging.get_transport(cfg.CONF) target = messaging.Target(topic='test') client = messaging.RPCClient(transport, target) ret= client.call(ctxt = {}, method = 'get_version',arg = 'hello world') print ret run server # python server.py --config-file ./config.cfg client # python client.py --config-file ./config.cfg version 1.0.0 server 显示 # python server.py --config-file ./config.cfg ------ GetVersion.get_version arg:hello world------- 概念详解 Transport This is a mostly opaque handle for an underlying messaging transport driver. RPCs and Notifications may use separate messaging systems that utilize different drivers, access permissions, message delivery, etc. To ensure the correct messaging functionality, the corresponding method should be used to construct a Transport object from transport configuration gleaned from the user's configuration and, optionally, a transport URL Transport是一个连接底层驱动的句柄，他通过读取config文件中transport_url这个参数，获取驱动url，并通过解析url加载传输数据所使用的驱动 在上面一节提到了config文件，如以下的url # vim config.cfg [DEFAULT] transport_url = rabbit://guest:guest@192.168.184.128:5672 即为加载RabbitDriver的驱动，最前面的rabbit代表了驱动的名称，驱动程序的具体位置在setup.cfg文件中，oslo.messaging.drivers这一个属性来定义，如官方实现的驱动如下 oslo.messaging.drivers = rabbit = oslo_messaging._drivers.impl_rabbit:RabbitDriver zmq = oslo_messaging._drivers.impl_zmq:ZmqDriver amqp = oslo_messaging._drivers.impl_amqp1:ProtonDriver # This driver is supporting for only notification usage kafka = oslo_messaging._drivers.impl_kafka:KafkaDriver # To avoid confusion kombu = oslo_messaging._drivers.impl_rabbit:RabbitDriver # This is just for internal testing fake = oslo_messaging._drivers.impl_fake:FakeDriver pika = oslo_messaging._drivers.impl_pika:PikaDriver 其中rabbit和kombu都会加载RabbitDriver，只是取了两个不同的名字而已 如果想使用其他驱动，只需修改config文件中transport_url参数，指向其他的驱动就可以了 Target Identifies the destination of messages A Target encapsulates all the information to identify where a message should be sent or what messages a server is listening for. Target是表示消息投递的目标用的，他就像写信的时的收件人地址一样，Target明确表示了这条消息应该投递到哪里，在server端，Target用来声明地址，在client端，用来表示目的地 Target类的参数 class Target(object): def __init__(self, exchange=None, topic=None, namespace=None, version=None, server=None, fanout=None, legacy_namespaces=None): exchange 与amqp中的exchange一样，用来定义一个交换机，可以指定一个独一无二的名字，也可以为空 为空的话，默认为\"openstack\"，这个默认值是通过oslo-config的默认参数来定义的，代码如下 cfg.StrOpt('control_exchange', default='openstack', help='The default exchange under which topics are scoped. May ' 'be overridden by an exchange name specified in the ' 'transport_url option.'), 如果想修改这个默认值的话，只需要在config文件中定义control_exchange就可以了，如下: [DEFAULT] transport_url = rabbit://guest:guest@192.168.184.128:5672 control_exchange = my_default_exchange topic 这里的topic与amqp中的topic概念不同，amqp中的topic是指的exchange的一种类型，而这里的topic，就是指的一个主题，或者是一个独一无二的routing_key，在oslo-message中，这也是路由消息必须配置的一个参数，而且是唯一一个必须配置的参数 在amqp的模型中，一个消息是通过两个参数来路由的，exchange name + routing_key 在oslo-message中，只需要定义一个topic就可以了，他将rpc简化为了只用一个topic路由的简单模型 namespace和version 在server端，Target也分为两类:server target和endpoint target server target 就是我们上面所说的，定义一个topic并接收消息 endpoint target是定义这个endpoint所属的范围，一个endpoint代表一个可调用对象，如我们上面例子中的GetVersion object就是一个endpoint，默认情况下，所有的endpoint都属于default namespace，为了将endpoint归类，引入了endpoint target概念,即一个endpoint可以归属于某个namespace，和其对应的version，书写方式如下 我们还是以上面例子中的GetVersion为例子 class GetVersion(object): target = oslo_messaging.Target(namespace='ns1', version='2.0') def get_version(self,ctx,arg): print \"------ GetVersion.get_version arg:%s--------\"%arg return \"version 1.0.0\" 给GetVersion类添加类属性target后，表示此endpoint属于namespace ns1，同时version为2.0 则client端在定义Target时，需要这样写 target = messaging.Target(topic='test',namespace='ns1',version='2.0') server server参数是在server端填写，是必填参数，用来唯一表示一个server client端可以填写server参数，也可以不填写，如果填写server，则按照指定的server进行投递 如果client端不填写server且有多个不同的server端监听了同一个topic的话，则按照server端注册的顺序，client对于这一topic的消息投递给第一个注册的server，后面注册的server将收不到投递的消息 fanout True/False 表示这个消息是否广播，默认为False，如果设置为True，则将此消息广播到每一个监听了此topic的server 注意，一旦设置为True，则server参数将失效，即使client端显示定义了server，也将不起作用，调用如下 import sys from oslo_config import cfg import oslo_messaging as messaging cfg.CONF(sys.argv[1:]) transport= messaging.get_transport(cfg.CONF) target = messaging.Target(topic='test',fanout=True) client = messaging.RPCClient(transport, target) ret= client.cast(ctxt = {}, method = 'get_version',arg = 'hello world') endpoint endpoint即rpc的方法实现体，可以定义为任意的python类中的函数，调用时使用函数名进行调用，无需对应类名，一个类可以定义一个rpc函数也可以定义多个rpc函数 需要注意的是，在创建server时会声明函数过滤器，这个过滤器会过滤可调用的函数名，默认情况下，只有以 _ 开头的函数会被过滤掉，其他函数均可以解析为rpc函数 get_rpc_server get_rpc_server函数，根据定义的transport、target、endpoints，创建rpc server handler 用一句话概括，就是使用配置的消息传递driver进行消息传递工具来监听target定义的topic并将收到的消息路由到endpoints进行处理 参数executor 可选参数executor，这个参数默认值是blocking，这个参数有三个值可以选择:blocking,eventlet和threading 这几个参数的区别如下: blocking: 处理函数单线程执行，即一次只能处理一个调用 eventlet: 处理函数用eventlet green thread pool来执行，可以同时处理多个消息 threading: 处理函数用pyhton thread pool执行，多线程可以同时处理多个消息 oslo-message同样是使用stevedore来加载不同的执行体，详见setup.cfg oslo.messaging.executors = blocking = futurist:SynchronousExecutor eventlet = futurist:GreenThreadPoolExecutor threading = futurist:ThreadPoolExecutor 参数access_policy 可选参数access_policy，可以解释为它是一个函数过滤器，这个参数指向了一个函数过滤器，负责执行endpoint可调用函数的过滤，如果不设置或者设置为None，则默认使用DefaultRPCAccessPolicy进行过滤 class DefaultRPCAccessPolicy(RPCAccessPolicyBase): def is_allowed(self, endpoint, method): return not method.startswith('_') 可以看到这个过滤器，只会阻止 _ 开头的函数，其他函数均可通过过滤 除了DefaultRPCAccessPolicy，还可以使用ExplicitRPCAccessPolicy class ExplicitRPCAccessPolicy(RPCAccessPolicyBase): \"\"\"Policy which requires decorated endpoint methods to allow dispatch\"\"\" def is_allowed(self, endpoint, method): if hasattr(endpoint, method): return hasattr(getattr(endpoint, method), 'exposed') return False 这个过滤器需要函数体拥有exposed属性，由于类函数是bound函数，不能设置属性，所以可以通过如下方式定义endpoint来使用ExplicitRPCAccessPolicy 还是通过GetVersion来举例 class GetVersion(object): def _get_version(self): def real_fun(ctx,arg): print \"------ GetVersion.get_version arg:%s--------\"%arg return \"version 1.0.0\" real_fun.exposed = True return real_fun def __getattr__(self, item): if item == \"get_version\": return self._get_version() 通过getattr将get_version调用转换为unbound函数，即可设置exposed属性 获取rpc server时这样获取 server = oslo_messaging.get_rpc_server(transport, target, endpoints, executor='blocking',access_policy=oslo_messaging.rpc.ExplicitRPCAccessPolicy) 如果想自己实现过滤器的话，编写子类继承oslo_messaging.rpc.RPCAccessPolicyBase并实现is_allowed函数即可 RPCClient RPCClient是client端进行消息发送的类 与rpc_server一样，RPCClient也是通过transport和target确定消息应该发送到何方 他有两个发送函数，分别是call和cast call def call(self, ctxt, method, **kwargs): call()方法用于调用远端rpc方法，并获取到一个返回值，因此调用call方法时，不能讲target的fanout属性设置为True call方法是一个同步方法，它会阻塞住当前线程，直到调用返回，或者是通过timeout参数设定超时时间 cast def cast(self, ctxt, method, **kwargs): cast()方法用于调用远端rpc方法，不获取返回值，这个方法常用于Target设置了fanout=True的广播调用 cast方法仅仅会阻塞线程到transport即driver层获取到此rpc调用，但是这个方法不保证rpc调用被远端server响应 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-23 17:52:21 "},"common_lib/oslo_messaging/rabbit_driver.html":{"url":"common_lib/oslo_messaging/rabbit_driver.html","title":"RabbitDriver解析","keywords":"","body":"上两章我们详细讲解了rabbitmq库kombu以及oslo-messaging的用法，乍一看oslo-messaging与kombu没有联系，实际上，oslo-messaging是通过RabbitDriver与kombu产生联系的，这一章，我们将分析oslo-messaging的默认driver RabbitDriver，从源码角度来解析RabbitDriver是如何将oslo-messaging的概念转化为rabbitmq的概念并通过kombu进行通信的 前言 The rabbit driver is the default driver used in OpenStack's integration tests. The driver is aliased as kombu to support upgrading existing installations with older settings. 上面这段话是openstack官方对RabbitDriver的介绍，大致意思为，RabbitDriver是openstack继承测试使用的默认driver，又名kombu oslo-message官方源码中实现了多个driver，除了kombu还有ZmqDriver、ProtonDriver、KafkaDriver、FakeDriver、PikaDriver，详细代码路径可以参考oslo_message目录下的setup.cfg中oslo.messaging.drivers这个entry_point 由于RabbitDriver是官方默认的driver，所以本文主要分析RabbitDriver的实现 RabbitDriver 我们在kombu这一章讲解了实现kombu的几个重要步骤，这里再复习一下，分别为 consumer端步骤 定义connection 定义exchange 定义queue，绑定exchange与routing_key 定义consumer，绑定queue与回调函数 启动服务，处理回调 producer端步骤 定义connection 定义exchange 定义producer 通过producer向exchange发送消息 既然RabbitDriver是对kombu的封装，那我们就从这几个kombu的实现步骤入手，看一下RabbitDriver是如何封装kombu的 consumer端 定义connection 加载RabbitDriver后，会调用RabbitDriver.init函数 class RabbitDriver(amqpdriver.AMQPDriverBase): def __init__(self, conf, url, default_exchange=None, allowed_remote_exmods=None): # ... connection_pool = pool.ConnectionPool( conf, max_size, min_size, ttl, url, Connection) super(RabbitDriver, self).__init__( conf, url, connection_pool, default_exchange, allowed_remote_exmods ) 这里的Connection为oslo_messaging/_drivers/impl_rabbit.Connection类，初始化父类AMQPDriverBase后，此connection_pool会保存在父类AMQPDriverBase的self._connection_pool属性中 graph TD A(MessageHandlingServer.start)-->B(RPCServer._create_listener) B-->C(Transport._listen) C-->D(AMQPDriverBase.listen) D-->E(self._get_connection) E-->F(rpc_common.ConnectionContext.__init__) F-->G(ConnectionPool.create) MessageHandlingServer是启动Rabbitmq server定义的类，在后面讲解如何使用RabbitDriver时会讲到 class ConnectionPool(Pool): def create(self, purpose=common.PURPOSE_SEND): return self.connection_cls(self.conf, self.url, purpose) 这里的connection_cls即为上面初始化的impl_rabbit.Connection类 在其init函数中，创建了kombu Connection class Connection(object): def __init__(self, conf, url, purpose): # ... self.connection = kombu.connection.Connection( self._url, ssl=self._fetch_ssl_params(), login_method=self.login_method, heartbeat=self.heartbeat_timeout_threshold, failover_strategy=self.kombu_failover_strategy, transport_options={ 'confirm_publish': True, 'client_properties': { 'capabilities': { 'authentication_failure_close': True, 'connection.blocked': True, 'consumer_cancel_notify': True }, 'connection_name': self.name}, 'on_blocked': self._on_connection_blocked, 'on_unblocked': self._on_connection_unblocked, }, ) # ... 定义exchange graph TD A(MessageHandlingServer.start)-->B(RPCServer._create_listener) B-->C(Transport._listen) C-->D(AMQPDriverBase.listen) D-->E(_drivers.impl_rabbit.Connection.declare_topic_consumer) E-->F(Consumer.__init__) class Consumer(object): def __init__(self, exchange_name,...) # ... self.exchange = kombu.entity.Exchange( name=exchange_name, type=type, durable=self.durable, auto_delete=self.exchange_auto_delete) 注意，如果在定义Target时没有指定exchange，这里使用的是默认的exchange，即\"openstack\",在oslo-messaging使用这一章有详细介绍 定义queue graph TD A(MessageHandlingServer.start)-->B(RPCServer._create_listener) B-->C(Transport._listen) C-->D(AMQPDriverBase.listen) D-->E(_drivers.impl_rabbit.Connection.declare_topic_consumer) class AMQPDriverBase(base.BaseDriver): def listen(self, target, batch_size, batch_timeout): conn = self._get_connection(rpc_common.PURPOSE_LISTEN) listener = AMQPListener(self, conn) conn.declare_topic_consumer(exchange_name=self._get_exchange(target), topic=target.topic, callback=listener) conn.declare_topic_consumer(exchange_name=self._get_exchange(target), topic='%s.%s' % (target.topic, target.server), callback=listener) conn.declare_fanout_consumer(target.topic, listener) return base.PollStyleListenerAdapter(listener, batch_size, batch_timeout) 这里创建了一个AMQPListener对象 创建了三个consumer:两个topic，一个fanout，其中两个topic中有一个添加了.server，这是RabbitDriver 将listener作为callback传入 def declare_topic_consumer(self, exchange_name, topic, callback=None, queue_name=None): \"\"\"Create a 'topic' consumer.\"\"\" consumer = Consumer(exchange_name=exchange_name, queue_name=queue_name or topic, routing_key=topic, type='topic', durable=self.amqp_durable_queues, exchange_auto_delete=self.amqp_auto_delete, queue_auto_delete=self.amqp_auto_delete, callback=callback, rabbit_ha_queues=self.rabbit_ha_queues) self.declare_consumer(consumer) graph TD E(_drivers.impl_rabbit.Connection.declare_topic_consumer)-->F(self.declare_consumer) F-->G(self.ensure) G-->H(self.ensure.execute_method) H-->I(self.declare_consumer._declare_consumer) I-->J(Consumer.declare) # oslo_messaging/_drivers/impl_rabbit.py class Consumer(object): def declare(self, conn): self.queue = kombu.entity.Queue( name=self.queue_name, channel=conn.channel, exchange=self.exchange, durable=self.durable, auto_delete=self.queue_auto_delete, routing_key=self.routing_key, queue_arguments=self.queue_arguments) self.queue.declare() self._declared_on = conn.channel 定义consumer 在我们上一章的kombu例子中，我们是这样定义consumer的 consumer = Consumer(conn.channel(),queues=[q],accept=['pickle', 'json'],callbacks=[_callback]) consumer.consume() 定义consumer的一个目标是绑定queue与回调函数 在RabbitDriver的实现中，他并没有像我们kombu例子中一样显式的定义Consumer对象，而是通过queue.comsumer函数来绑定queue与回调的，这个具体的步骤会在下一节讲到 为了印证这一点，我们先来看一下kombu源码中对于Consumer.consume()函数的实现 # kombu/messaging.py class Consumer(object): ... def consume(self, no_ack=None): ... self._basic_consume(queue, no_ack=no_ack, nowait=True) ... def _basic_consume(self, queue, consumer_tag=None, no_ack=no_ack, nowait=True): ... queue.consume(tag, self._receive_callback, no_ack=no_ack, nowait=nowait) .. 实际上Consumer对象也是间接的调用了queue.consume()函数来绑定回调 所以在RabbitDriver中，他直接省掉了定义Consumer这一步 启动服务，处理回调 调用MessageHandlingServer.start启动服务 得到ListenAdapter graph TD A(MessageHandlingServer.start)-->B(RPCServer._create_listener) B-->C(Transport._listen) C-->D(AMQPDriverBase.listen) def listen(self, target, batch_size, batch_timeout): listener = AMQPListener(self, conn) # ... return base.PollStyleListenerAdapter(listener, batch_size, batch_timeout) MessageHandlingServer._create_listener()最终得到一个PollStyleListenerAdapter类型的对象,文件位置oslo_messaging/_drivers/base.py class MessageHandlingServer(service.ServiceBase, _OrderedTaskRunner): def start(self, override_pool_size=None): # ... self.listener = self._create_listener() # ... self.listener.start(self._on_incoming) 然后PollStyleListenerAdapter.star得到调用，传入的回调函数是self._on_incoming self._poll_style_listener类型为amqpdriver.AMQPListener class PollStyleListenerAdapter(Listener): def __init__(self, poll_style_listener, batch_size, batch_timeout): # ... self._poll_style_listener = poll_style_listener self._listen_thread = threading.Thread(target=self._runner) # ... def start(self, on_incoming_callback): super(PollStyleListenerAdapter, self).start(on_incoming_callback) self._started = True self._listen_thread.start() start中启动了一个线程，线程执行体是self._runner def _runner(self): while self._started: incoming = self._poll_style_listener.poll( batch_size=self.batch_size, batch_timeout=self.batch_timeout) if incoming: self.on_incoming_callback(incoming) self._poll_style_listener类型为amqpdriver.AMQPListener class AMQPListener(base.PollStyleListener): def poll(self, timeout=None): # ... while not self._shutdown.is_set(): self._message_operations_handler.process() if self.incoming: return self.incoming.pop(0) # ... self.conn.consume(timeout=min(self._current_timeout, left)) # ... if self.incoming: return self.incoming.pop(0) 我们可以看到在poll中的操作可以分为，先从消息队列中获取消息并放入到self.incoming容器中，然后判断self.incoming中是否有消息，如果有，取一个消息并且返回 先看一下self.conn.consume这个函数 graph TD A(impl_rabbit.Connection.consume)-->B(self.ensure) B-->C(self.ensure.execute_method) C-->D(self.consume._consume) class Connection(object): def consume(self, timeout=None): # ... def _consume(): # ... # while self._new_tags: for consumer, tag in self._consumers.items(): if tag in self._new_tags: consumer.consume(self, tag=tag) self._new_tags.remove(tag) while True: # ... self.connection.drain_events(timeout=poll_timeout) # ... consumer.consume这一步是声明回调函数，通过_new_tags标志来控制只声明一次 class Consumer(object): def consume(self, conn, tag): # ... self.queue.consume(callback=self._callback, consumer_tag=six.text_type(tag), nowait=self.nowait) # ... self._callback是在创建queue时传进来的AMQPListener对象 self.connection.drain_events是告诉kombu connection去队列里拿消息，收到消息后，回调函数得到调用，即AMQPListener对象得到调用 这里用到了python的可调用对象特性，即将对象当做函数进行调用时，对象的call方法响应 # oslo_messaging/_drivers/amqpdriver.py class AMQPListener(base.PollStyleListener): def __call__(self, message): # ... self.incoming.append(AMQPIncomingMessage( self, ctxt.to_dict(), message, unique_id, ctxt.msg_id, ctxt.reply_q, self._obsolete_reply_queues, self._message_operations_handler) self.incoming中有了数据后，调用堆栈在回到PollStyleListenerAdapter._runner def _runner(self): while self._started: incoming = self._poll_style_listener.poll( batch_size=self.batch_size, batch_timeout=self.batch_timeout) if incoming: self.on_incoming_callback(incoming) self.on_incoming_callback是MessageHandlingServer.start时传入的回调函数self._on_incoming self.listener.start(self._on_incoming) 看一下self._on_incoming函数 def _on_incoming(self, incoming): self._work_executor.submit(self._process_incoming, incoming) self._work_executor是利用stevedore加载的执行插件，初始化在init函数 class MessageHandlingServer(service.ServiceBase, _OrderedTaskRunner): def __init__(self, transport, dispatcher, executor='blocking'): # ... mgr = driver.DriverManager('oslo.messaging.executors', self.executor_type) self._executor_cls = mgr.driver # ... _executor_cls默认是用的executor='blocking' 在setup.cfg中的定义如下 oslo.messaging.executors = blocking = futurist:SynchronousExecutor eventlet = futurist:GreenThreadPoolExecutor threading = futurist:ThreadPoolExecutor 可以看到blocking的类为futurist:SynchronousExecutor 初始化worker的位置在MessageHandlingServer.start函数 class MessageHandlingServer(service.ServiceBase, _OrderedTaskRunner): def start(self, override_pool_size=None): # ... self._work_executor = self._executor_cls(**executor_opts) # ... SynchronousExecutor是一个同步执行的工具，调用submit时传入函数执行体和参数 则self._process_incoming得到调用 对象实例是oslo_messaging/rpc/server.RPCServer class RPCServer(msg_server.MessageHandlingServer): def _process_incoming(self, incoming): message = incoming[0] # ... res = self.dispatcher.dispatch(message) # ... 调用dispatch分发数据 # oslo_messaging/rpc/dispatcher.py class RPCDispatcher(dispatcher.DispatcherBase): def dispatch(self, incoming): message = incoming.message ctxt = incoming.ctxt method = message.get('method') args = message.get('args', {}) namespace = message.get('namespace') version = message.get('version', '1.0') for endpoint in self.endpoints: target = getattr(endpoint, 'target', None) if not target: target = self._default_target if not (self._is_namespace(target, namespace) and self._is_compatible(target, version)): continue if hasattr(endpoint, method): if self.access_policy.is_allowed(endpoint, method): return self._do_dispatch(endpoint, method, ctxt, args) 获取client消息中的method函数名 获取client消息中的函数参数args 获取client消息中的namespace和version 循环保存的self.endpoints 检查endpoint是否定义了namespace和version，如果没有定义，则用default值 与client传过来namespace和version进行比对 获取endpoint中的method方法并执行 producer端 RabbitDriver在producer端关于kombu的实现，可以集中在AMQPDriverBase.send这个函数中，我们下面就来着重分析这个函数 oslo_messaging/_drivers/amqpdriver.py graph TD A(AMQPDriverBase.send)-->B(AMQPDriverBase._send) def _send(self, target, ctxt, message, wait_for_reply=None, timeout=None, envelope=True, notify=False, retry=None): ... with self._get_connection(rpc_common.PURPOSE_SEND) as conn: if notify: exchange = self._get_exchange(target) conn.notify_send(exchange, target.topic, msg, retry=retry) elif target.fanout: conn.fanout_send(target.topic, msg, retry=retry) else: topic = target.topic exchange = self._get_exchange(target) if target.server: topic = '%s.%s' % (target.topic, target.server) conn.topic_send(exchange_name=exchange, topic=topic, msg=msg, timeout=timeout, retry=retry) ... 分析这段函数 使用self._get_connection获取连接，在上面讲解consumer时注重介绍了这个函数，这里不再做说明 根据notify，fanout，topic的定义顺序确定是使用哪种模式进行发送 notify 这是RabbitDriver实现的notification功能，我们本章只分析rpc相关，暂时不分析notification fanout def fanout_send(self, topic, msg, retry=None): \"\"\"Send a 'fanout' message.\"\"\" exchange = kombu.entity.Exchange(name='%s_fanout' % topic, type='fanout', durable=False, auto_delete=True) self._ensure_publishing(self._publish, exchange, msg, retry=retry) 定义了一个fanout类型的exchange def _publish(self, exchange, msg, routing_key=None, timeout=None): ... with self._transport_socket_timeout(timeout): self._producer.publish(msg, exchange=exchange, routing_key=routing_key, expiration=timeout, compression=self.kombu_compression) 使用通过producer.publish发送出去 topic topic这里与直接用kombu不同的是，如果设置了server属性，则topic需要加上server组成kombu的topic，相当于是RabbitDriver添加的一个server概念 def topic_send(self, exchange_name, topic, msg, timeout=None, retry=None): \"\"\"Send a 'topic' message.\"\"\" exchange = kombu.entity.Exchange( name=exchange_name, type='topic', durable=self.amqp_durable_queues, auto_delete=self.amqp_auto_delete) self._ensure_publishing(self._publish, exchange, msg, routing_key=topic, timeout=timeout, retry=retry) 定义一个topic类型的exchange，并通过publish函数发出 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-23 16:05:55 "},"common_lib/oslo_db/define.html":{"url":"common_lib/oslo_db/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"common_lib/oslo_log/define.html":{"url":"common_lib/oslo_log/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"core_plugin/define.html":{"url":"core_plugin/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"service_plugin/define.html":{"url":"service_plugin/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"mechanism_driver/define.html":{"url":"mechanism_driver/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"openvswitch/define.html":{"url":"openvswitch/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"ovn/define.html":{"url":"ovn/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "},"mechanism_self/define.html":{"url":"mechanism_self/define.html","title":"简介","keywords":"","body":"Writing,please wait 写作中，请等待 By 曹云涛，使用知识共享 署名-非商业性使用-禁止演绎 4.0 国际 许可协议发布            此页面修订于： 2019-07-24 13:45:51 "}}